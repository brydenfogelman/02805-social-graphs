{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Part A: Structure of the the philosopher network\n",
    "\n",
    "First create graphs from philosopher files, using custom module to help load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re, json, urllib2, operator\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "import community as cm\n",
    "%matplotlib inline\n",
    "\n",
    "# custom module used for philosopher files\n",
    "import philosophers as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './philosophers/remove_words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75490033cd92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use custom module to get unique list of all philosophers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munique_philosophers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pattern used to match links, only matches content before the piped character if present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ex. Aristotle (philosopher) | Aristotle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brydenfogelman/DTU/social-graphs/02805-social-graphs/bryden/philosophers.pyc\u001b[0m in \u001b[0;36mcombined\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mphils_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m# create a list which contains all the philosphers (including repeats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mcombined_philosphers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brydenfogelman/DTU/social-graphs/02805-social-graphs/bryden/philosophers.pyc\u001b[0m in \u001b[0;36mlists\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# create a set which contains words we want to remove (including philosphers with missing links)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mremove_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphilosophers_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/remove_words.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mremove_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './philosophers/remove_words.txt'"
     ]
    }
   ],
   "source": [
    "# use custom module to get unique list of all philosophers\n",
    "unique_philosophers = ph.combined()\n",
    "\n",
    "# pattern used to match links, only matches content before the piped character if present\n",
    "# ex. Aristotle (philosopher) | Aristotle\n",
    "pattern = r'\\[\\[([^|\\[\\]]*)\\|?[^|\\[\\]]*\\]\\]';\n",
    "\n",
    "# Create directed graph\n",
    "directed_phil_network = nx.DiGraph()\n",
    "# Add philosophers as nodes\n",
    "directed_phil_network.add_nodes_from(unique_philosophers)\n",
    "\n",
    "# store results of links to use later\n",
    "content_map = {}\n",
    "\n",
    "# file_load will return a tuple containing the name of the \n",
    "for data in ph.file_load():\n",
    "    phil_node = data[0]\n",
    "    content = data[1]\n",
    "    # load content\n",
    "    # retrieve all links found on page\n",
    "    if content:  # can remove this if wikicontent function is modified\n",
    "        all_links = re.findall(pattern, str(content.encode('utf8')))\n",
    "        # find only links to other philosophers\n",
    "        # convert lists to sets and perform an intersection between unique_philosophers and all_links \n",
    "        phil_links = set(all_links).intersection(set(unique_philosophers))\n",
    "        \n",
    "        # save philosopher as key and links as value\n",
    "        content_map[phil_node] = phil_links\n",
    "        \n",
    "        # add edges\n",
    "        ebunch = [(phil_node, phil) for phil in phil_links]\n",
    "        directed_phil_network.add_edges_from(ebunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create undirected network from directed network\n",
    "undirected_phil_network = nx.Graph(directed_phil_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the the philosopher network\n",
    "\n",
    "* Find the 5 most central philosophers according to betweenness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort dictionary by values and then create a new list with all values as tuples\n",
    "def display_centrality(dct, N, name):\n",
    "    values = sorted(dct.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for ii in range(0,N):\n",
    "        phil = values[ii]\n",
    "        print \"The %s has a %s of %s\" % (phil[0],name,phil[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate betweenness centrality\n",
    "betweenness_centrality = nx.betweenness_centrality(directed_phil_network)\n",
    "# use helper function to quickly sort dict and print\n",
    "display_centrality(betweenness_centrality, 5, 'betweenness_centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What role do you imagine philosophers with high wikipedia graph betweenness centrality play in the history of philosophy?**\n",
    "\n",
    ">Betweeness centrality measures how central a node is. Philosophers with a high betweenness centrality could have been very influential too other philosophers. One possibility is that the philosopher is a 'father' of a field or sub-field of philosophy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the 5 most central philosophers according to eigenvector centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similar procedure to the above\n",
    "eigenvector_centrality = nx.eigenvector_centrality(directed_phil_network)\n",
    "display_centrality(eigenvector_centrality, 5, 'eigenvector_centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate centrality corresponding to both in- and out-edges (see NetworkX documentation for details).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_centrality = nx.in_degree_centrality(directed_phil_network)\n",
    "\n",
    "print \"In Centrality:\"\n",
    "display_centrality(in_centrality, 5, 'in_centrality')\n",
    "\n",
    "out_centrality = nx.out_degree_centrality(directed_phil_network)\n",
    "\n",
    "print \"\\nOut Centrality:\"\n",
    "display_centrality(out_centrality, 5, 'out_centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How is eigenvector centrality difference from degree centrality?**\n",
    "\n",
    ">Degree centrality is a measure of the amount links a node has while eigenvector centraility is a measure of how important a node is. A large difference is that eigenvector centrality places more importance on what nodes that it is connected to while degree centrality is more concerned about the degree of its own node and the highest degree node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare your results for eigenvector centrality to the results for betweenness centrality - does the difference make sense when you read the philosopher's wikipedia pages?**\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the undirected version of the graph assortative with respect do degree? (e.g. do high-degree philosophers tend to link to other high-degree philosophers, and low-degree philosophers to other low-degree philosophers?). Provide an interpretation of your answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assortativity = nx.degree_assortativity_coefficient(undirected_phil_network)\n",
    "print assortativity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It appears that the philosopher network is slightly dissortative which is what we should expect. In general high-degree philosophers should tend to link with other high-degree philosophers and low-degree philosophers. Low-degree philosophers will tend to link with more popular philosophers and not low-degree philosophers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and structure in the philosopher network\n",
    "\n",
    "* Create a histogram of the number of philosophers born in every century, starting 500 BC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data from url and convert to python object\n",
    "response = urllib2.urlopen('https://dl.dropboxusercontent.com/u/153071/02805/philosopher_birth_year.json')\n",
    "data = json.loads(response.read())\n",
    "birth_year = [v for v in data.values() if v >= -500]\n",
    "bins = int((max(birth_year) + 500) / 100)\n",
    "hist, bin_edges = np.histogram(birth_year,bins)\n",
    "\n",
    "bin_dist = abs(bin_edges[1] - bin_edges[0])\n",
    "plt.bar(bin_edges[:-1], hist, width = bin_dist)\n",
    "plt.plot(bin_edges[:-1], hist, 'r')\n",
    "plt.xlabel('Birth Year')\n",
    "plt.ylabel('Total Number')\n",
    "plt.title('Number of Philosophers born in a certain time period ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe the plot. Does philosophy seem to have developed at a steady pace - or in a more bursty manner? Are we living in a golden age of philosophy right now? (Use the data & common sense to present an argument for your answer).**\n",
    "\n",
    "> The plot shows an almost exponential increase of philosophers. According the plot it seems Philosophy has seemed to develop at a rapid pace but when population growth is considered, that is not the case. I don't believe we are in a golden age of philosphy because if you consider the drastic increase of population the amount of philophers per capita is about the same as now and in 500 BC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the undirected version of the graph assortative with respect to age? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create subgraph with philosophers in philosopher_birth_year.json\n",
    "directed_phil_age_network = directed_phil_network.subgraph(data.keys())\n",
    "undirected_phil_age_network = nx.Graph(directed_phil_age_network)\n",
    "\n",
    "# create new dict that contains only nodes in subgraph\n",
    "age_dict = {}\n",
    "for node in directed_phil_age_network.nodes():\n",
    "    age_dict[node] = data[node]\n",
    "    \n",
    "# set age attribute to node\n",
    "nx.set_node_attributes(directed_phil_age_network, 'age', age_dict)\n",
    "\n",
    "undirected_phil_age_network = nx.Graph(directed_phil_age_network)\n",
    "# calculate attribute assortativity\n",
    "assortativity = nx.attribute_assortativity_coefficient(undirected_phil_age_network,'age')\n",
    "\n",
    "print assortativity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not assortive, could be the result of two effects counteracting each other. Old philosophers being more famous and referenced more could counteract with an overall increase of philosophers as the year increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A reasonable hypothesis is that old philosophers are more famous. Create a scatter-plot of age versus in-degree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_degrees = directed_phil_age_network.in_degree()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for phil,age in nx.get_node_attributes(directed_phil_age_network, 'age').iteritems():\n",
    "    x.append(age)\n",
    "    y.append(in_degrees[phil])\n",
    "    \n",
    "plt.plot(x,y,'.')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('In Degrees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Do you see a correlation between the two? Justify your answer (for example by calculating the correlation coefficient.) **\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: The branches of philosophy. Are they communities?\n",
    "\n",
    "### Modularity\n",
    "\n",
    "**Explain the concept of modularity in your own words.**\n",
    "\n",
    "> Modularity is the measure of difference between the fraction of all communities inside a network and the amount of links a community has if it was random. A higher modularity would correspond to a fewer then expected links between communities.\n",
    "\n",
    "* Creating a set of six new branches, where we take all of the philosophers that belong to more than one branch and assign them to the branch that they have the most connections to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use helper module to grab lists of philosophers and then convert them to sets\n",
    "branches = list(map(set,ph.lists()))\n",
    "\n",
    "# combine all the lists of philosophers into one list\n",
    "all_philosophers = []\n",
    "for lst in ph.lists():\n",
    "    all_philosophers += lst\n",
    "\n",
    "# create a list of philosophers that appear more then once\n",
    "repeated_philosophers = []\n",
    "for phil in unique_philosophers:\n",
    "    # if the philosopher appears in more then one list, add it to the repeated philosophers list\n",
    "    if all_philosophers.count(phil) > 1:\n",
    "        repeated_philosophers.append(phil)\n",
    "        # then remove the philosopher from all branches\n",
    "        for branch in branches:\n",
    "            if phil in branch:\n",
    "                branch.remove(phil)\n",
    "        \n",
    "# for each philosopher that appeared more then twice\n",
    "for phil in repeated_philosophers:\n",
    "    # user the content_map to find the think the philospher has\n",
    "    links = content_map[phil]\n",
    "    \n",
    "    target_branch = 0\n",
    "    max_val = 0\n",
    "    # then for every branch, calculate the amount of links\n",
    "    for ii in range(0,len(branches)):\n",
    "        branch = branches[ii]\n",
    "        # calculate length of the intersection between the links and a branch\n",
    "        val = len(links.intersection(branch))\n",
    "        # check to see if the current branch has more links with the phil then the max branch\n",
    "        if val > max_val:\n",
    "            # save the index of the branch that has the most links\n",
    "            target_branch = ii\n",
    "            max_val = val\n",
    "    # add the philosopher the branch it has the most links\n",
    "    branches[target_branch].add(phil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use equation 9.12 in the book to calculate the modularity M of the branches-partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph is the same as made previously\n",
    "\n",
    "# number of communities\n",
    "N = len(branches)\n",
    "\n",
    "# total edges\n",
    "L = undirected_phil_network.number_of_edges()\n",
    "\n",
    "modularity = 0\n",
    "for community in branches:\n",
    "    total_degree = sum(undirected_phil_network.degree(community).values())\n",
    "    \n",
    "    # still contains links that could be outside the community\n",
    "    num_links = undirected_phil_network.edges(community)\n",
    "    \n",
    "    # iterate through nodes in list of edges and remove links that leave the community\n",
    "    for nodes in num_links:\n",
    "        # if the first node or second node is not in the community remove that edge\n",
    "        if nodes[0] not in community or nodes[1] not in community :\n",
    "            num_links.remove(nodes)\n",
    "            \n",
    "    # calculate partial modularity\n",
    "    modularity += len(num_links) / L - (total_degree / (2 * L)) ** 2\n",
    "    \n",
    "print \"Modularity of the Philosopher Network is %s\" % modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The value of M is > 0 so the branches are good communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Community detection in the full philosopher network.\n",
    "\n",
    "### Community detection on the full philosopher network\n",
    "\n",
    "* Use the Python Louvain-algorithm implementation to find communities in the full philosopher network. Report the value of modularity found by the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partition = cm.best_partition(undirected_phil_network)\n",
    "\n",
    "modularity = cm.modularity(partition, undirected_phil_network)\n",
    "\n",
    "print \"Modularity of the Philosopher Network is %s using the Louvain-algorithm\" % modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is it higher or lower than what you found above for the branches as communities? What does this comparison reveal about the branches?\n",
    "\n",
    "> This is lower then found above for the branches as communities. This reveals that the branches are a good choice for communities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the communities found by your algorithm with the branches of philosophy by creating a matrix D with dimension (B times C), where B is the number of branches and C is the number of communities. We set entry D(i,j) to be the number of nodes that branch i has in common with community j. The matrix D is what we call a confusion matrix. Use the confusion matrix to explain how well the communities you've detected correspond to the labeled branches of philosophy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_val = 0\n",
    "partial_list = set([])\n",
    "partitions = []\n",
    "for phil in sorted(partition.items(), key=operator.itemgetter(1)):\n",
    "    next_val = phil[1]\n",
    "    if prev_val == next_val:\n",
    "        partial_list.add(phil[0])\n",
    "    else:\n",
    "        prev_val = next_val\n",
    "        partitions.append(partial_list)\n",
    "        partial_list = set([])\n",
    "        partial_list.add(phil[0])\n",
    "        \n",
    "# append last value \n",
    "partitions.append(partial_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = len(partitions)\n",
    "B = len(branches)\n",
    "D = np.zeros(shape=(B,C))\n",
    "for ii in xrange(0,B):\n",
    "    branch = branches[ii]\n",
    "    for jj in xrange(0,C):\n",
    "        community = partitions[jj]\n",
    "        D[(ii,jj)] = len(branch.intersection(community))\n",
    "        \n",
    "print np.shape(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
